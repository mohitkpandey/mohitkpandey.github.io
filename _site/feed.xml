<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://mohitkpandey.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mohitkpandey.github.io/" rel="alternate" type="text/html" /><updated>2020-11-15T12:03:26-06:00</updated><id>https://mohitkpandey.github.io/feed.xml</id><title type="html">Mohit Pandey</title><subtitle>Ph.D. Candidate</subtitle><author><name>Mohit Pandey</name><email>pandey.mohitk@gmail.com</email></author><entry><title type="html">Encoder - Attention - Decoder</title><link href="https://mohitkpandey.github.io/posts/2020/11/En-Att-De/" rel="alternate" type="text/html" title="Encoder - Attention - Decoder" /><published>2020-11-10T00:00:00-06:00</published><updated>2020-11-10T00:00:00-06:00</updated><id>https://mohitkpandey.github.io/posts/2020/11/Encoder-Att-Decode</id><content type="html" xml:base="https://mohitkpandey.github.io/posts/2020/11/En-Att-De/">&lt;p&gt;&lt;strong&gt;Explaining Attention Network in Encoder-Decoder setting using Recurrent Neural Networks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Encoder-Decoder paradigm has become extremely popular in deep learning particularly in the space of natural language processing. Attention modules complement encoder-decoder architecture to make learning more close to humans way. I present a gentle introduction to encode-attend-decode. I  provide motivation for each block and explain the math governing the model. Further, I break down the code into digestible bits for each mathematical equation. While there are good explanations to attention mechanism for machine translation task, I will try to explain the same for a sequence tagging task (Named Entity Recognition).&lt;/p&gt;

&lt;div style=&quot;width:image width px; font-size:80%; text-align:center;&quot;&gt;&lt;img src=&quot;../../../../files/images/encode_attend_decode.jpg&quot; width=&quot;50%&quot; height=&quot;50%&quot; style=&quot;padding-bottom:0.5em;&quot; /&gt;&lt;b&gt;Encode-Attend-Decode Architecture&lt;/b&gt;&lt;/div&gt;

&lt;p&gt;In the next part of the series, I will use the architecture explained here to solve the problem of &lt;a href=&quot;/posts/2020/11/TFJS-NER/&quot;&gt;Named Entity Recognition&lt;/a&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;encoder&quot;&gt;Encoder&lt;/h2&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;Encode the source/input sequence into a meaningful representation containing information about the input sentence. In case of a problem involving images, this could be penultimate dense layer of a convolutional neural network. We’ll see handling textual input in more detail.&lt;/p&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) are extremely suited to model sequential or temporal data. Text fits this category well. When a human reads a sentence, they process the current word they are reading $x_t$ while remembering what they had processed until then ${h_{t-1}}$. We model this using an RNN as follows&lt;/p&gt;

\[h_t = RNN(h_{t-1},x_{t})\]

&lt;p&gt;where, $h_t$ is the hidden state of RNN (GRU/LSTM) at $t^{th}$ time-step. ${x_t}$ is a vectorial representation of the word (e.g. Word vector, Bag of Words etc.). &lt;br /&gt;
For t = T, $h_T$ becomes our thought vector. In absence of an attention network, this thought vector is the input to decoder at decoder’s time-step $0$. i.e.&lt;/p&gt;

\[S_0 = h_T\]

&lt;p&gt;we’ll talk more about $s_t$ in &lt;a href=&quot;#decoder&quot;&gt;decoder&lt;/a&gt; section.&lt;/p&gt;

&lt;h3 id=&quot;implementation-details-with-mathematical-explanation-and-code&quot;&gt;Implementation details with mathematical explanation and code&lt;/h3&gt;

&lt;p&gt;Implementing encoder is a 2 step process.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If each word in the sentence is converted to a &lt;em&gt;d&lt;/em&gt; dimension word vector, $x_i \in R^d$. Every sentence is normalized to same length T, typically equal to the longest sentence in the corpus. This is done by padding &amp;lt;PAD&amp;gt; token to shorter sentences. Consequently, each sentence in our dataset $Sent^{(i)}$ with T words becomes $Sent^{(i)} \in R^{T \times d} $. Following picture helps me visualize this&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../../../../files/images/sent_dim.png&quot; style=&quot; margin-right: 5px;&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;This is easy to translate to code&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#MAX_SEQUENCE_LENGTH = T
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#words_input = [1,T] :1 = batchsize (for simplifying explanation)
#EMBEDDING_DIM = d (200 for used pretrained word2vec)
#embedding_tensor = weights from pretrained embedding. Dim: |Vocab| x d
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_vocab_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;input_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;trainable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#x = vectorized sentence (Sent_i):[1,T,d] :1 = batchsize (for simplifying explanation)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If there are $h$ units in each RNN (LSTM/GRU) block, each hidden RNN unit will produce an $h$ dimensional output called &lt;em&gt;hidden state&lt;/em&gt;. &lt;span style=&quot;color:gray&quot;&gt;&lt;em&gt;(Additionally we also get another output called cell state if using an LSTM. I’ll write another blog-post detailing workings of LSTMs and GRUs, meanwhile there’s an excellent explanation &lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;here&lt;/a&gt;&lt;/em&gt;)&lt;/span&gt;.
Each $h_t \in R^h$. Note there are always T hidden units, one corresponding to each word. This would mean that output of the RNN block (RNN block comprises of all the $T$ hidden units together), will be in $R^{T \times h}$&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c1&quot;&gt;#num_hidden_units = h
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GRU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_hidden_units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'RNN_Layer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#outputs = [1,T,h] :1 = batchsize
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;In absence of the attention module, we only care for RNN output from last time-step $T$ as that ($h_T$) will be our &lt;em&gt;thought vector&lt;/em&gt; (input to the decoder). For this, set &lt;code&gt;return_sequences = False&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;attention&quot;&gt;Attention&lt;/h2&gt;

&lt;h3 id=&quot;motivation-1&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;The basic attention network courtesy &lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Bahdanau et al.&lt;/a&gt; was originally proposed to solve and maximize the machine translation performance. However, it has been shown to perform exceedingly well in a wide variety of other downstream tasks as well such as NER, question answering, image classification etc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A very primitive intuition to this idea of attention is to model human behavior towards sequence processing. Consider the task of question answering. The objective is to answer questions based upon understanding of a document (paragraph). The encoder encodes the entire sentence into one fixed dimension vector $h_T, (thought vector)$. It’s unreasonable to expect this fixed vector to be equally effective in encoding the information from early time-steps $t \lt\lt T$ just as well as it would at $t\approx T$. RNN’s are prone to vanishing gradients hence making such a learning even harder. 
&lt;br /&gt;A human on the other hand would not typically read the entire document (input) in order to make inferences. Humans pay selective focus (attention) to different parts of the sentence guided by the objective of the downstream task. So to answer a question about authorship of a document, a human reader will focus primarily on beginning of the document. An attention network tries to emulate this by learning to attend to different parts of the sentence with varying intensity (energy).&lt;/p&gt;

&lt;p&gt;The ability of attention network to assign higher scores to important phrases in texts and patches in images makes for interesting visualization and provides an interesting way for model explanation. In the case of Named Entity Recognition, the hope is that an attention module will learn to attend to most significant words, phrases and tokens that guide the classification of each word into classes (PER, MISC, LOC, ORG). In essence, we should see high attention score for words that belong to one of the named entity. For an example sentence to detect named entity, attention scores for relevant classes may look like following. You may play with more sentences &lt;a href=&quot;/posts/2020/11/TFJS-NER/#demo&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../../../files/images/att-ner-vis.png&quot; style=&quot; margin-right: 5px;&quot; width=&quot;100%&quot; height=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;implementation-details-with-mathematical-explanation-and-code-1&quot;&gt;Implementation details with mathematical explanation and code&lt;/h3&gt;
&lt;p&gt;For each time-step of the decoder, the attention mechanism computes a weighted sum of importance over all the words in the input sequence. In place of the thought-vector, this weighted sum is fed to the decoder. Attention mechanism proceeds through a three step process.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Calculation of Energy Scores&lt;/strong&gt; $ e_{jt} $&lt;/p&gt;

    &lt;p&gt;This is defined as importance of the $j^{th}$ word when making inference about the $t^{th}$ word of the decoder. Bahdanau described this for machine translation task where $j \neq t$. In our example of NER however, $j=t $ since there exists a label (PER, MISC, LOC, ORG or None) for each $t \in (1,T)$ of our input sentence. Hence, we’ll have for each class in our labelset, an energy score for every word in the input sentence. For a sentence, &lt;code&gt;I like London&lt;/code&gt;, we’ll have a 3 $(T)$ dimensional vector. $ e_{jt} $ is defined as following&lt;/p&gt;

\[e_{jt} = V_a^T tanh(W_as_{t-1}+U_ah_j)\]

    &lt;p&gt;where $s_{t-1}$ is the previous time-step of the decoder. &lt;br /&gt;
In our example, we can ignore $s_{t-1}$ as there is no dependence on predicted class (tag) of previous word on predicting tag of current word by the decoder. So our energy score $e_j$ becomes&lt;/p&gt;

\[e_{j} = V_a^T tanh(U_ah_j)\]

    &lt;p&gt;We’ll rewrite this equation to make dimensions consistent in this post&lt;/p&gt;

\[e_{j} = [tanh(h_jU_a)]V_a^T\]

    &lt;p&gt;Let’s look at the dimensions&lt;/p&gt;

    &lt;p&gt;$h_j \in R^h$ i.e. $R^{1 \times h}$(see &lt;a href=&quot;#encoder&quot;&gt;encoder&lt;/a&gt;)&lt;br /&gt;
$U_a \in R^{h \times d_a}$ &lt;br /&gt;
$h_jU_a \in R^{1 \times d_a }$ &lt;br /&gt;
$tanh(h_jU_a) \in R^{1 \times d_a}$ &lt;br /&gt;
$V_a \in R^{1 \times d_a} $ &lt;br /&gt;
$V_a^T \in R^{d_a \times 1} $ &lt;br /&gt;
$[tanh(U_ah_j)]V_a^T \in R^{1}$ &lt;br /&gt;
$d_a$ is usually chosen as $h/2$&lt;/p&gt;

    &lt;p&gt;We get a scalar energy score for each word. For entire sequence of $T$ words, our $h \in R^{h \times t}$. Similarly, in all other dimensions 1 is replaced by $T$. Ultimately, we get a $T$ dimensional energy vector with an energy score scalar for every word in our sentence. Let’s see how to code this&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#hidden layer = tanh(Ua x h), outputs: from encoder [1,T,h]
#hidden_layer :[1,T,d_a]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tanh'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#energy vector = (tanh(h x Ua)).Va
#energy_vector : [1,T,1]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;energy_vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Calculation of attention scores&lt;/strong&gt; $ \alpha_{j} $&lt;/p&gt;

    &lt;p&gt;In deep learning, we often normalize scores into probabilities by taking softmax. This helps us make more intuitive sense of the numbers yielded. Keeping up with this spirit, we convert our energy scores to attention scores as
\(\alpha_j = softmax(e_j)\)
This yields an &lt;em&gt;attention vector&lt;/em&gt; in $R^T$ with an attention score corresponding to each word in the input sentence. This attention vector is typically used for visualizing model’s learning.&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#attention_vector : [1,T]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'attention_vector'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;energy_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Calculation of context vector &lt;em&gt;c&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Finally we calculate the context vector that is the attention weighted sum of learned representations of words by the encoder. In case of an NER, this context vector is fed to the decoder and helps the decoder how much focus (attention) it should pay to each word when deciding the class label for each word in the input sentence. &lt;span style=&quot;color:gray&quot;&gt;&lt;em&gt;(In a machine translation setting, each time-step (t) of the decoder gets a different context vector $c_t$).&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;

\[c = \sum_{j=1}^T \alpha_jh_j\]

    &lt;div style=&quot;width:image width px; font-size:80%; text-align:center;&quot;&gt;&lt;img src=&quot;../../../../files/images/context_vector.jpg&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;padding-bottom:0.5em;&quot; /&gt;Context Vector&lt;/div&gt;

    &lt;p&gt;From the figure, it’s clear that each $c_j$ will be a $h \times T$ dimension matrix (same as &lt;em&gt;outputs&lt;/em&gt; from encoder).&lt;/p&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;c1&quot;&gt;#Repeating and transposing attention_vector 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#to make matrix multiplication with outputs possible 
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RepeatVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_hidden_units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Permute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;decoder&quot;&gt;Decoder&lt;/h2&gt;

&lt;h3 id=&quot;motivation-2&quot;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;Now that we have the context vector, which seems to be a more meaningful and powerful way to encode the source sentences, we are ready to make inferences. The choice of the decoder architecture is governed by the downstream task at hand. When the objective is to generate text (like in machine translation or text summarization), often the decoder is made with an RNN. The hidden states of this decoder RNN are denoted by $s_t$. In our example of NER, our decoder will be simply a dense, fully connected layer with softmax to out prediction probabilities. A more complex variant of decoder for the same problem is also possible.&lt;/p&gt;

&lt;h3 id=&quot;implementation-details-with-mathematical-explanation-and-code-2&quot;&gt;Implementation details with mathematical explanation and code&lt;/h3&gt;
&lt;p&gt;Keeping the decoder simple, we pass our &lt;em&gt;context vectors&lt;/em&gt; through a fully connected layer followed by a softmax layer. While the number of units in the fully connected layer can be chosen arbitrarily, the softmax is equal to the number of possible classes. In our example, this would be all possible named entity tags.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_fc_units&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'prediction'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Presented here is an overview of the vanilla attention network by Bahdanau et al. This &lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html&quot;&gt;blog-post&lt;/a&gt; presents a survey on other variants of attention and an introduction to Transformers.&lt;/p&gt;</content><author><name>Mohit Pandey</name><email>pandey.mohitk@gmail.com</email></author><category term="Attention" /><category term="NLP" /><category term="RNN" /><category term="Text Classification" /><category term="Keras" /><summary type="html">Explaining Attention Network in Encoder-Decoder setting using Recurrent Neural Networks Encoder-Decoder paradigm has become extremely popular in deep learning particularly in the space of natural language processing. Attention modules complement encoder-decoder architecture to make learning more close to humans way. I present a gentle introduction to encode-attend-decode. I provide motivation for each block and explain the math governing the model. Further, I break down the code into digestible bits for each mathematical equation. While there are good explanations to attention mechanism for machine translation task, I will try to explain the same for a sequence tagging task (Named Entity Recognition). Encode-Attend-Decode Architecture In the next part of the series, I will use the architecture explained here to solve the problem of Named Entity Recognition</summary></entry><entry><title type="html">Named entity recognition with simple Attention</title><link href="https://mohitkpandey.github.io/posts/2020/11/TFJS-NER/" rel="alternate" type="text/html" title="Named entity recognition with simple Attention" /><published>2020-11-10T00:00:00-06:00</published><updated>2020-11-10T00:00:00-06:00</updated><id>https://mohitkpandey.github.io/posts/2020/11/TFJS-NER</id><content type="html" xml:base="https://mohitkpandey.github.io/posts/2020/11/TFJS-NER/">&lt;p&gt;NER implementation hosted within browser using Tensorflow-JS.&lt;/p&gt;

&lt;p&gt;Definition from &lt;a href=&quot;https://en.wikipedia.org/wiki/Named-entity_recognition&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Named Entity Recognition is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, etc.
See &lt;a href=&quot;/posts/2020/11/TFJS-NER/#demo&quot;&gt;&lt;b&gt;&lt;em&gt;demo&lt;/em&gt;&lt;/b&gt;&lt;/a&gt; below. Continue reading for model explanation and code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--more--&gt;
&lt;h3 id=&quot;demo&quot;&gt;Demo&lt;/h3&gt;

&lt;head&gt;
      &lt;meta name=&quot;description&quot; content=&quot;Testing Simple Machine Learning Model into an WebApp using TensorFlow.js&quot; /&gt;
      &lt;meta name=&quot;keywords&quot; content=&quot;Machine Learning, TensorFlow.js&quot; /&gt;
      &lt;meta name=&quot;author&quot; content=&quot;Mohit Pandey&quot; /&gt;
      &lt;meta charset=&quot;UTF-8&quot; /&gt;
      &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
      &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot; /&gt;
      &lt;meta name=&quot;description&quot; content=&quot;TensorFlow js demo for Named-entity recognition (NER) (Sequence Tagging task). Implemented with Keras (GloVe + GRU RNN) and tensorflow.js&quot; /&gt;
      &lt;meta property=&quot;og:title&quot; content=&quot;Named-entity recognition TensorFlow.js demo&quot; /&gt;
      &lt;meta property=&quot;og:description&quot; content=&quot;TensorFlow js demo for Named-entity recognition (NER) (Sequence Tagging task). Implemented with Keras (GloVe + GRU RNN) and tensorflow.js&quot; /&gt;
      &lt;link rel=&quot;stylesheet&quot; href=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css&quot; integrity=&quot;sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T&quot; crossorigin=&quot;anonymous&quot; /&gt;
      &lt;style&gt;
         .demo {
         margin: 2em auto;
         }
         .main-result {
         margin: 3em auto;
         }
         .result {
         padding: 1em;
         }
         .demo-header {
         font-size: 1.0rem;
         margin: 0.5em;
         }
         .tags-review {
         margin-top: 1.5rem;
         }
         .divider{
          width:5px;
          height:auto;
          display:inline-block;
          }
         .btn-primary { background-color: red; }

      &lt;/style&gt;
      
   &lt;/head&gt;
&lt;body&gt;
      &lt;!--  &lt;script src=&quot;https://code.jquery.com/jquery-2.2.4.min.js&quot;&gt;&lt;/script&gt;
         &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.5.2/dist/tf.min.js&quot;&gt;&lt;/script&gt; --&gt;
      &lt;main role=&quot;main&quot; class=&quot;container&quot;&gt;
         &lt;p&gt;
            Enter sentence like &lt;code&gt;Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract bovine spongiform encephalopathy.&lt;/code&gt;
            or &lt;code&gt;She likes David!&lt;/code&gt;.
         &lt;/p&gt;
         &lt;div class=&quot;card demo&quot;&gt;
            &lt;div class=&quot;card-header&quot;&gt;
               &lt;!-- &lt;h1 class=&quot;demo-header&quot;&gt;
                  Dehcmcmo! --&gt;
                  &lt;!-- &lt;div class=&quot;loading-model spinner-border text-primary&quot; role=&quot;status&quot;&gt;
                     &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
                  &lt;/div&gt; --&gt;
               &lt;!-- &lt;/h1&gt; --&gt;
               &lt;form class=&quot;form&quot; onkeypress=&quot;return event.keyCode != 13;&quot;&gt;
                  &lt;div class=&quot;form-group mx-sm-3 md-2&quot;&gt;
                     &lt;input type=&quot;text&quot; class=&quot;form-control form-control-xs&quot; id=&quot;input_text&quot; placeholder=&quot;Enter short sentence&quot; /&gt;
                  &lt;/div&gt;
                  &lt;div class=&quot;d-flex justify-content-center&quot;&gt;
                     &lt;button type=&quot;button&quot; class=&quot;btn btn-primary&quot; id=&quot;get_ner_button&quot;&gt;Search Entities&lt;/button&gt;
                     &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
                     &lt;button type=&quot;button&quot; class=&quot;btn btn-primary&quot; id=&quot;clear_bttn&quot;&gt;Clear&lt;/button&gt;
                  &lt;/div&gt;
               &lt;/form&gt;
            &lt;/div&gt;
            &lt;div class=&quot;result main-result&quot;&gt;&lt;/div&gt;
            &lt;div class=&quot;result attention-bar&quot; id=&quot;attention_bar&quot;&gt;&lt;/div&gt;
            &lt;div class=&quot;result tags-result&quot;&gt;&lt;/div&gt;
         &lt;/div&gt;
      &lt;/main&gt;
      &lt;script src=&quot;https://code.jquery.com/jquery-3.3.1.slim.min.js&quot; integrity=&quot;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
      &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js&quot; integrity=&quot;sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
      &lt;script src=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js&quot; integrity=&quot;sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;
      &lt;!-- &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.1/dist/tf.min.js&quot;&gt;&lt;/script&gt; --&gt;
      &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest&quot;&gt; &lt;/script&gt;
      &lt;script src=&quot;https://cdn.plot.ly/plotly-latest.min.js&quot;&gt;&lt;/script&gt;
      &lt;script src=&quot;../../../../files/model/tfjs-ner/vocabs.js&quot;&gt;&lt;/script&gt;
      &lt;script src=&quot;../../../../files/model/tfjs-ner/predict.js&quot;&gt;&lt;/script&gt;
      
   &lt;/body&gt;</content><author><name>Mohit Pandey</name><email>pandey.mohitk@gmail.com</email></author><category term="Tensorflow-JS" /><category term="NLP" /><category term="RNN" /><category term="Text Classification" /><category term="Keras" /><summary type="html">NER implementation hosted within browser using Tensorflow-JS. Definition from Wikipedia Named Entity Recognition is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, etc. See demo below. Continue reading for model explanation and code.</summary></entry><entry><title type="html">Seq2Seq Machine Translation</title><link href="https://mohitkpandey.github.io/posts/2020/11/seq2seq/" rel="alternate" type="text/html" title="Seq2Seq Machine Translation" /><published>2020-11-08T00:00:00-06:00</published><updated>2020-11-08T00:00:00-06:00</updated><id>https://mohitkpandey.github.io/posts/2020/11/Seq2seq</id><content type="html" xml:base="https://mohitkpandey.github.io/posts/2020/11/seq2seq/">&lt;p&gt;I explore Seq2Seq model in Pytorch to build a neural machine translation system. &lt;span style=&quot;color:red&quot;&gt;&lt;strong&gt;Currently the system translates from German to English.&lt;/strong&gt;&lt;/span&gt; 
In this series, I will explore 
various state-of-the-art NLP architectures to build NMT systems algorithms and hope to focus on English to Hindi translation. 
I will also attempt to provide simplified mathematical explanations of the models as well as implementation details. 
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;First on this list is Sequence-to-Sequence model using encoder-decoder paradigm. Check the &lt;b&gt;DEMO&lt;/b&gt; below.&lt;/p&gt;

&lt;html&gt;
&lt;head&gt;
  
&lt;script&gt;
  function sendData()
  {
      let request = new XMLHttpRequest();
      url = &quot;http://127.0.0.1:8008/predict/&quot;+document.getElementById('src').value
      request.open(&quot;GET&quot;, url);
      request.send();
      request.onload = () =&gt; {
        console.log(request);
        if (request.status === 200) {
          // by default the response comes in the string format, we need to parse the data into JSON
          document.getElementById('trg').value= request.response;//JSON.parse(request.responseText));
        } else {
          console.log(`error ${request.status} ${request.statusText}`);
        }
      };

  }

&lt;/script&gt;

&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;Please enter short German sentence&lt;/h2&gt;
Seperate punctuations with a space &lt;i&gt;( zwei junge weiße männer sind im freien in der nähe vieler büsche . )&lt;/i&gt;
&lt;form&gt;
    &lt;label for=&quot;sep_len&quot;&gt;Source Sentence&lt;/label&gt; &lt;input id=&quot;src&quot; name=&quot;sep_len&quot; type=&quot;text&quot; value=&quot;&quot; /&gt;
    &lt;br /&gt;
    &lt;label for=&quot;sep_len&quot;&gt;Target Sentence&lt;/label&gt; &lt;input id=&quot;trg&quot; name=&quot;sep_len&quot; type=&quot;text&quot; value=&quot;&quot; /&gt;
    &lt;br /&gt;
    &lt;input type=&quot;button&quot; onclick=&quot;sendData()&quot; value=&quot;Translate&quot; /&gt;

&lt;/form&gt;

&lt;/body&gt;
&lt;/html&gt;

&lt;!-- Much has been written lately about the increasing militarization of US
law enforcement. One of the most visible indicators of this shift in
recent decades is the increased frequency of tactical gear and equipment
worn and carried by police officers. However, this pales in comparison
to images of police departments bringing armored vehicles to peaceful
protests.  People often criticize police departments or SWAT
teams for owning and deploying tanks in situations that don’t warrant
their use. In reality, these ‘tanks’ are typically [Mine-Resistant
Ambush Protected](https://en.wikipedia.org/wiki/MRAP) (MRAP) vehicles.
MRAPs were developed by the US military and produced by various
manufacturers from 2007-2009. As their name suggests, they are designed
to protect passengers from an improvised explosive device (IED) attack.

Given the extreme threat they were designed to survive, MRAPs are
emblematic of increasing police militarization in the US. But how did
police come to own these military-grade vehicles?

# Where have all the MRAPs gone?

Police departments, sheriff’s offices, and even school districts (the LA
Unified School District [briefly owned an
MRAP](https://www.lamag.com/citythinkblog/lausd-keys-mrap-tank/) in 2014
before [returning it to the Department of
Defense](https://www.dailynews.com/2014/11/21/lausd-school-police-return-armored-military-vehicle-which-is-now-in-barstow/))

 --&gt;</content><author><name>Mohit Pandey</name><email>pandey.mohitk@gmail.com</email></author><category term="pytorch" /><category term="machine translation" /><category term="heroku" /><category term="seq2seq" /><summary type="html">I explore Seq2Seq model in Pytorch to build a neural machine translation system. Currently the system translates from German to English. In this series, I will explore various state-of-the-art NLP architectures to build NMT systems algorithms and hope to focus on English to Hindi translation. I will also attempt to provide simplified mathematical explanations of the models as well as implementation details.</summary></entry><entry><title type="html">Digit Classification</title><link href="https://mohitkpandey.github.io/posts/2020/11/digit-class/" rel="alternate" type="text/html" title="Digit Classification" /><published>2020-11-01T00:00:00-05:00</published><updated>2020-11-01T00:00:00-05:00</updated><id>https://mohitkpandey.github.io/posts/2020/11/Digit-Classification</id><content type="html" xml:base="https://mohitkpandey.github.io/posts/2020/11/digit-class/">&lt;p&gt;&lt;b&gt;Digit Recognition using Deep Learning&lt;/b&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;
This page is best viewed &lt;a href=&quot;https://mohitpandey.netlify.app/posts/2020/11/digit-class/&quot;&gt;here&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Webapp to recognize handwritten digits between 0 and 9. Model trained 
using Keras and served using Tensorflow.js
&lt;!--more--&gt;&lt;/p&gt;

&lt;html&gt;
   &lt;head&gt;
      &lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;
      &lt;!-- &lt;script  src=&quot;https://www.googletagmanager.com/gtag/js?id=G-H0NW5Z2MYC&quot;&gt;&lt;/script&gt; --&gt;
      &lt;!-- &lt;script&gt;
         window.dataLayer = window.dataLayer || [];
         function gtag(){dataLayer.push(arguments);}
         gtag('js', new Date());
         
         gtag('config', 'G-H0NW5Z2MYC');
      &lt;/script&gt; --&gt;
      &lt;title&gt;Digit Recognition WebApp&lt;/title&gt;
      &lt;meta name=&quot;description&quot; content=&quot;Testing Simple Machine Learning Model into an WebApp using TensorFlow.js&quot; /&gt;
      &lt;meta name=&quot;keywords&quot; content=&quot;Machine Learning, TensorFlow.js&quot; /&gt;
      &lt;meta name=&quot;author&quot; content=&quot;Mohit Pandey&quot; /&gt;
      &lt;style&gt;
         body {
         touch-action: none; /*https://developer.mozilla.org/en-US/docs/Web/CSS/touch-action*/
         font-family: &quot;Roboto&quot;;
         }
         h1 {
         margin: 50px;
         font-size: 70px;
         text-align: center;
         }
         #paint {
         border:3px solid red;
         margin: auto;
         }
         #predicted { 
         font-size: 18px;
         margin-top: 5px;
         text-align: center;
         }
         #number {
         border: 3px solid black;
         margin: auto;
         margin-top: 5px;
         text-align: center;
         vertical-align: middle;
         }
         #clear {
         margin: auto;
         margin-top: 5px;
         padding: 5px;
         text-align: center;
         }
      &lt;/style&gt;
   &lt;/head&gt;
   &lt;body&gt;
      &lt;!--&lt;script type=&quot;text/javascript&quot; src=&quot;http://livejs.com/live.js&quot;&gt;&lt;/script&gt;--&gt;
      &lt;script src=&quot;https://code.jquery.com/jquery-2.2.4.min.js&quot;&gt;&lt;/script&gt;
      &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.5.2/dist/tf.min.js&quot;&gt;&lt;/script&gt;
      &lt;!--     &lt;h1&gt;Digit Recognition WebApp&lt;/h1&gt; --&gt;
      &lt;div id=&quot;paint&quot;&gt;
         &lt;canvas id=&quot;myCanvas&quot;&gt;&lt;/canvas&gt;
      &lt;/div&gt;
      &lt;div id=&quot;predicted&quot;&gt;
         Recognized digit
         &lt;div id=&quot;number&quot;&gt;&lt;/div&gt;
         &lt;button id=&quot;clear&quot;&gt;Clear&lt;/button&gt;
      &lt;/div&gt;
      &lt;script&gt;
         var isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
         if (isMobile) {
           $('#paint').css({'width': '100%'});
           $('#number').css({'width': '30%', 'font-size': '50px'});
           $('#clear').css({'font-size': '18px'});
         } else {
           $('#paint').css({'width': '300px'});
           $('#number').css({'width': '150px', 'font-size': '120px'});
           $('#clear').css({'font-size': '18px'});
         }
         
         var cw = $('#paint').width();
         $('#paint').css({'height': cw + 'px'});
         
         cw = $('#number').width();
         $('#number').css({'height': cw + 'px'});
         
         // From https://www.html5canvastutorials.com/labs/html5-canvas-paint-application/
         var canvas = document.getElementById('myCanvas');
         var context = canvas.getContext('2d');
         
         var compuetedStyle = getComputedStyle(document.getElementById('paint'));
         canvas.width = parseInt(compuetedStyle.getPropertyValue('width'));
         canvas.height = parseInt(compuetedStyle.getPropertyValue('height'));
         
         var mouse = {x: 0, y: 0};
         
         canvas.addEventListener('mousemove', function(e) {
           mouse.x = e.pageX - this.offsetLeft;
           mouse.y = e.pageY - this.offsetTop;
         }, false);
         
         context.lineWidth = isMobile ? 20 : 25;
         context.lineJoin = 'round';
         context.lineCap = 'round';
         context.strokeStyle = '#0000FF';
         
         canvas.addEventListener('mousedown', function(e) {
           context.moveTo(mouse.x, mouse.y);
           context.beginPath();
           canvas.addEventListener('mousemove', onPaint, false);
         }, false);
         
         canvas.addEventListener('mouseup', function() {
           // $('#number').html('&lt;img id=&quot;spinner&quot; src=&quot;spinner.gif&quot;/&gt;');
           canvas.removeEventListener('mousemove', onPaint, false);
           var img = new Image();
           img.onload = function() {
             context.drawImage(img, 0, 0, 28, 28);
             data = context.getImageData(0, 0, 28, 28).data;
             var input = [];
             for(var i = 0; i &lt; data.length; i += 4) {
               input.push(data[i + 2] / 255);
             }
             predict(input);
           };
           img.src = canvas.toDataURL('image/png');
         }, false);
         
         var onPaint = function() {
           context.lineTo(mouse.x, mouse.y);
           context.stroke();
         };
         
         tf.loadLayersModel('../../../../files/model/digit-class/model.json').then(function(model) {
           window.model = model;
         });
         
         // http://bencentra.com/code/2014/12/05/html5-canvas-touch-events.html
         // Set up touch events for mobile, etc
         canvas.addEventListener('touchstart', function (e) {
           var touch = e.touches[0];
           canvas.dispatchEvent(new MouseEvent('mousedown', {
             clientX: touch.clientX,
             clientY: touch.clientY
           }));
         }, false);
         canvas.addEventListener('touchend', function (e) {
           canvas.dispatchEvent(new MouseEvent('mouseup', {}));
         }, false);
         canvas.addEventListener('touchmove', function (e) {
           var touch = e.touches[0];
           canvas.dispatchEvent(new MouseEvent('mousemove', {
             clientX: touch.clientX,
             clientY: touch.clientY
           }));
         }, false);
         
         var predict = function(input) {
           if (window.model) {
             window.model.predict([tf.tensor(input).reshape([1, 28, 28, 1])]).array().then(function(scores){
               scores = scores[0];
               predicted = scores.indexOf(Math.max(...scores));
               $('#number').html(predicted);
             });
           } else {
             // The model takes a bit to load, if we are too fast, wait
             setTimeout(function(){predict(input)}, 50);
           }
         }
         
         $('#clear').click(function(){
           context.clearRect(0, 0, canvas.width, canvas.height);
           $('#number').html('');
         });
      &lt;/script&gt;
   &lt;/body&gt;
&lt;/html&gt;</content><author><name>Mohit Pandey</name><email>pandey.mohitk@gmail.com</email></author><category term="Image Classification" /><category term="MNIST" /><summary type="html">Digit Recognition using Deep Learning This page is best viewed here Webapp to recognize handwritten digits between 0 and 9. Model trained using Keras and served using Tensorflow.js</summary></entry></feed>